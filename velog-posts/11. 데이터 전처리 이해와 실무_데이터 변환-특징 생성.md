<p>데이터 변환 내 새로운 특징을 생성하기 위한 방안이 어떤 것이 있는지 알아보자.</p>
<h3 id="feature-creation">Feature Creation</h3>
<p>주어진 원본 데이터의 조합/변환 등을 기반하여 새로운 특징들을 구축 및 생성하는 방법이다. 특징은 원데이터의 변환을 통해 생성되는 특징을 새롭게 생성하여 모델링을 적용하기 위해 분석 과정 내 성능과 효율성을 확보하고자 한다. </p>
<p>feature engineering
원시 데이터로 부터 적절하고 올바른 특징을 만들어내는 일련의 과정이다. </p>
<p>목적 및 필요성)</p>
<ul>
<li>품질 확보 : raw 데이터 활용 기반의 모델링은 품질 확보 어려움</li>
<li>최적환된 형태 변환 : 분석 목적에 따라 효과적인 feature를 확보하는 것이 중요</li>
</ul>
<h3 id="특징-생성-방안">특징 생성 방안</h3>
<ul>
<li>범주 인코딩 : 순서가 없는 경우와 순서가 있는 경우로 나뉘는 범주형 변수<ul>
<li>순서가 정해져 있으면 높고 낮음의 의미가 담김<ul>
<li>단위가 커질수록 의미가 부여된다</li>
</ul>
</li>
<li>수치적 데이터가 아닌경우에는 모델에 적용하기 어려움</li>
</ul>
</li>
<li>결합 및 분해 : 변수들의 조합을 기반으로 새로운 특징을 구축하는 방법<ul>
<li>변수 간의 연산으로 특징을 구축</li>
</ul>
</li>
<li>차원 축소 : 고차원의 원시 데이터셋을 저차원으로 축소<ul>
<li>저차원 축소 시에 새로운 특징을 생성</li>
</ul>
</li>
</ul>
<h3 id="범주-인코딩">범주 인코딩</h3>
<p>범주형 데이터의 알고리즘 적용을 위한 수치형 변환이다. 알고리즘 데이터의 경우는 범주형은 사용이 불가능하기 때문에 수치형 변수로 데이터를 변화해주어야 한다. </p>
<ul>
<li><strong>one-hot encoding</strong> : 순서의 의미를 지니지 않은 범주형 변수를 처리하는 방법<ul>
<li>k개의 범주를 지닌 범주형 변수를 k개의 변수로 변환하는 방법이다. </li>
<li>사용할 데이터의 범주가 매우 많을 경우에는 고려가 필요하다. <ul>
<li>각 범주의 요소마다 별도 컬럼으로 생성하여 true/false를 표현</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="결합-및-분해">결합 및 분해</h3>
<p>변수의 결합과 분해를 기반으로 새로운 특징을 생성할 수 있다. 파생변수를 생성할 때 고려되는 방안이다.</p>
<h4 id="결합">결합</h4>
<p>수치형 데이터의 경우에는 사칙연산을 기반으로 결합이 이루어진다. </p>
<ul>
<li>add/divide/subtract : 합계/평균는 종합적으로 데이터를 파악하고, 편차의 경우 특정 데이터의 편중 정도를 파악한다. </li>
<li>multiply : 상호작용 항으로 컬럼들의 시너지 효과를 파악한다.<ul>
<li>사전 도메인 지식 기반으로 특징 생성 검토가 반드시 필요하다. </li>
</ul>
</li>
</ul>
<h4 id="분해">분해</h4>
<p>변수의 분해를 통해서 새로운 의미를 지닌 특징을 생성한다. 특정 변수 활용 기반의 새로운 의미를 파악할 수 있는 특징을 생성하는 방법이다. </p>
<ul>
<li>separate</li>
</ul>
<h3 id="차원-축소">차원 축소</h3>
<p>차원 축소의 목적에 따라 주성분 분석과 군집 분석을 통해 새로운 특징을 생성할 수 있다. </p>
<h4 id="주성분-분석pca">주성분 분석,PCA</h4>
<p>변수들이 지닌 정보를 최대한 확보하는 저차원 데이터로 생성한다. PCA(Principal component analysis)</p>
<p>n개의 변수를 지닌 데이터를 n차원이라고 한다면, 주성분은 n개 이하가 된다. </p>
<ul>
<li>서로 연관된 변수들이 관측되었을 때, 주성분은 <strong>원본 데이터 분산 기반</strong>의 특징을 생성한다. </li>
<li><strong>주성분 간의 서로 독립</strong>을 이루도록 구성한다. </li>
</ul>
<p>pc1은 원본 데이터의 분포를 가장 많이 보존하는 pc2는 pc1과 독립적이고 데이터의 분포를 많이 보존한다. <img alt="" src="https://velog.velcdn.com/images/ehekaanldk/post/1f74c40f-0dba-4cef-8fa2-640a4ce8c1d8/image.png" /></p>
<p>분포를 많이 보존하는 것이 정보를 많이 보존하는 것과 동일하다.
주성분(PC)의 수는 분석가 판단으로 설정할 수 있다. </p>
<h4 id="군집-분석">군집 분석</h4>
<p>군집 분석 기반의 고차원 데이터를 하나의 특징으로 차원 축소한다. featurization via clustering</p>
<p>군집 분석이란 여러 범주를 지닌 레코드들 끼리의 유사성을 보고 유사한 데이터들끼리 하나의 클러스터를 구성하는 것을 말한다. </p>
<p>군집 결과 특징을 새로운 분류나 회귀 알고리즘의 입력 변수로 활용하는 stacking 방법도 있다. </p>
<p>원본 데이터의 여러 개의 특징을 하나의 특징으로 축소하여 모델 연산 비용이 감소한다. </p>
<p>군집결과가 해당 원래 관측치들을 반영해야 한다. </p>
<h4 id="실습">실습</h4>
<p>실습 시 활용 패키지
. pandas
. numpy
. scikit-lear
· matplotlib
· seabor</p>
<p>데이터 : 구매 시점 이력 정보 데이터 </p>
<p>범주 인코딩 : 숫자로 표현되지 않은 데이터를 수치형으로 표현하고 모델링에 적용하기 위한 과정</p>
<p>one-hot encoding은 <strong>get_dummies 함수</strong>를 활용하여 쉽게 구현이 가능하다. pd.get_dummies(데이터명, columns=['컬럼명'])</p>
<hr />
<p>결합 및 분해 기반의 특징 생성</p>
<p>연/월/일 등을 분석가 시준에 맞추어 시간대의 의미를 지닌 신규 파생 변수로 분해 및 결합이 가능하다. </p>
<pre><code># date 컬럼을 연/월/일/요일 등의 의미를 지닌 변수로 분해
creation_data['year'] = creation_data['date'].dt.year #연도
creation_data['month'] = creation_data['date'].dt.month #월
creation_data['day'] = creation_data['date'].dt.day #일
creation_data['hour'] = creation_data['date'].dt.hour #시간
creation_data['dayofweek'] = creation_data['date'].dt.dayofweek #요일 (월 = 0)
creation_data.head()</code></pre><hr />
<p>PCA(주성분 분석)</p>
<p>여러 개의 변수를 지닌 고차원 데이터를 저차원으로 변환하도록 주성분들을 생성하는 알고리즘</p>
<p>데이터 분석 목적이 병리적 특성을 파악해서 악성과 양성을 구분하기 위함 임으로 데이터를 input과 target(진단 컬럼)으로 나눈다. </p>
<p>주성분 분석 이전에 가장 먼저 수행해야 하는 것은 표준화이다. 수치형 변수들의 범위가 다 다르기 때문에 표준화를 수행한다. </p>
<pre><code>from sklearn.preprocessing import StandardScaler
std_scaler = StandardScalerI)

#Input값을 scaling 실행 후 번한
std_scaler.fit(input_df)
input_scaled = std_scaler.transform(input_df)

# array 형태로 변환됨
input_scaled</code></pre><p>주성분 분석을 수행한다. 30개의 변수를 지닌 데이터를 2개의 주성분만 유지되도록 한다. </p>
<pre><code># 주성분 분석 수행
from sklearn decomposition import PCA

# 두 개 주성분만 유지시키도록 수행
# 30개 변수의 데이터를 2개의 주성분으로 남도록 변한

pca = PCA(n_components=2)
pca.fit(input_scaled)
X_pca = pca.transform(input_scaled)
X_pca</code></pre><p>pca결과를 시각화하여 나타낸다. </p>
<pre><code># 2개의 주성분으로 구성된 컬럼들이 Target을 구분하기에 효율적인지 시각화로 확인
import matplotlib.pyplot as plt
import seaborn as sns

#산점도로 2개의 주성분을 시각화
ax = sns.scatterplot(x='pcl', y= 'pc2', data =X_pca_df)</code></pre><p>target의 악성과 양성를 본다. </p>
<pre><code># Target과 확인을 위해 주성분 분석을 수행한 Input 데이터와 기존 Target 데이터를 Merge
# pca_df 생성 : 2개의 주성분 (Input) 및 1개의 Target (diagnosis)
target_df = target_df.reset_index()
pca_df = pd.merge (X_pca_df, target_df, left_index = True, right_index= True, how = 'inner' )
pca_df = pca_df [['pcl', 'pc2'. 'diagnosis']]
pca_df</code></pre><p>2개의 주성분을 악성과 양성의 산점도로 본다. </p>
<pre><code># 클래스를 색깔로 구분하여 처음 두 개의 주성분으로 Target과 비교
ax = sns.scatterplot(x='pc1', y= 'pc2', hue = 'diagnosis', data =pca_df, palette=['green','red'] )</code></pre><p>전체 분산의 최소 80프로 수준에서 설명하는 수준의 주성분을 확보할 수 있다. pca = PCA(n_components = 0.8)</p>
<pre><code># 전체 분산의 최소 80% 수준에서 설명하는 수준의 주성분 확보
pca = PCA(n_components= 0.8)
pca.fit(input_scaled)
X_pca = pca. transform( input_scaled)
X_pca_df = pd.DataFrame(X_pca)
X_pca_df</code></pre><hr />
<p>군집분석 clustering</p>
<p>해당 데이터를 하나의 변수로 변환해 차원을 축소한다. </p>
<pre><code>from sklearn.cluster import KMeans

# 일부 변수만 선택 (30개 변수 중 15개의 변수만 임의로 선정)
# 즉, 활용할 정보의 양을 절반으로 축소
subset_df= input_df.iloc[:, 0:15]
subset_df</code></pre><pre><code># 데이터 스케일링
std_scaler.fit(subset_df)
subset_input_scaled = std_scaler.transform(subset_df)
subset_input_scaled</code></pre><p>군집의 수를 사전에 정의해야한다. </p>
<pre><code># K-means 클러스터링 활용
# 군집 Label수 설정
k = 5
mode| = KMeans(n_clusters = k, random_state = 10)</code></pre><pre><code># scaling 한 데이터를 fit하여 모할 학습
model.fit(subset_input_scaled)

# 글러스터링 결과를 타겟 변수와 비교하기 위하여 원 데이터에
target_df ['cluster'] = model.fit_predict(subset_input_scaled |
럼으로 생성</code></pre><p>5개의 군집으로 나누어진 것이 악성과 양성에 얼마나 반영하는지 확인해 본다. </p>
<pre><code># 15개의 임의의 변수로 만들어진 하나의 특징(군집결과)과 기존 Target 변수 비교
pd.crosstab(target_df.diagnosis, target_df.cluster)</code></pre><p>• 임의의 15개 변수만을 활용한 하나의 특징(군집 결과)이 Target 구분에 효과적일 것임을 예측 가능함
• 이처럼 많은 변수를 하나의 특징으로 구성하고, 업력 데이터의 차원을 줄인다면 모델 연산 비용 절감에 효과적이다. </p>
<p>정리)
범주형 데이터 변환
• One-hot Encoding 기반의 변환을 통해 데이터 처리</p>
<p>변수 결합 및 분해 기반 특징 구축
• 기존 데이터를 활용하여 변수 간의 조합을 통해 신규 특징 구축</p>
<p>차원 축소 기반 특징 생성
• 고차원 원시 데이터를 저차원 데이터로 축소하도록 새로운 특징을 생성</p>