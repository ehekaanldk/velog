---
title: "ML_앙상블/랜덤포레스트"
date: "2025-04-03"
link: "https://velog.io/@ehekaanldk/ML%EC%95%99%EC%83%81%EB%B8%94%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8"
series: "Uncategorized"
---

<h3 id="앙상블-학습이란">앙상블 학습이란?</h3>
<p>집단지성으로 어려운 문제도 쉽게 해결책을 찾을 수 있는 것처럼, 앙상블 학습을 통한 분류는 여러 개의 분류기(classifier)를 생성하고 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법</p>
<ul>
<li>앙상블 학습의 목표 : 단일 분류기보다 신뢰성이 높은 예측값을 얻는 것</li>
<li>이미지, 영상, 음성 등의 비정형 데이터의 분류는 딥러닝에서 뛰어난 성능</li>
<li>대부분의 정형 데이터 분류 시에는 앙상블이 뛰어난 성능</li>
</ul>
<hr />
<p>앙상블 학습의 유형</p>
<ol>
<li>보팅(voting)</li>
<li>배깅(bagging)</li>
<li>부스팅(boosting)</li>
</ol>
<p>먼저 보팅과 배깅을 비교하면, 여러개의 분류기가 투표를 통해서 최종 예측을 결정하는 방식이라는 공통점을 가지고 있다. 
다른점은 
보팅의 경우 동일한 데이터에 대해서 서로 다른 알고리즘을 가진 분류기를 결합하는 방식, 
배깅은 각각의 분류기가 모두 같은 유형의 알고리즘(보통 결정트리)이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 하는 방식이다. </p>
<p>일반적으로 보팅에서 결합하는 방식은 다수결(hard voting)이나 확률 평균(soft voting)방식을 사용해 결과를 합칩니다. </p>
<p>배깅을 자세히 설명하면서 부트스트랩이라는 개념이 나오게 되는데 이는 중복을 허용하는 방식으로 복원추출을 의미합니다. 배깅은 보팅과 학습하는 데이터 세트가 다르다.
<strong>부트스트랩</strong>은 원본 학습 데이터를 샘플링해 추출해서 개별 분류기에게 데이터를 샘플링해서 추출하는 방식
배깅은 각 분류기가 샘플링된 데이터 세트에 대해서 학습을 통해 개별적인 예측을 수행한 결과를 보팅으로 최종 예측결과를 선정하는 방식</p>
<p>부스팅은 여러 개의 분류기가 순차적으로 학습하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서, 올바른 예측을 위해 <strong>다음 분류기에게 가중치를 부여하여 학습</strong>을 진행하는 것
분류기에게 가중치를 부여하여 학습하는 것을 부스팅이라 한다. 대표적인 예시인 xgboost와 LightGBM은 캐글에서 많이 사용하는 알고리즘</p>
<hr />
<h3 id="랜덤포레스트">랜덤포레스트</h3>
<p>랜덤포레스트는 배깅 방법의 대표적인 알고리즘이다.</p>
<p>부트스트래핑 분할 방식으로 구한 서브 데이터세트 데이터에 대해서 여러 개의 결정 트리가 개별적으로 학습을 수해한 뒤에 최종적으로 모든 분류기가 보팅르 총해 예측을 결정한다. </p>
<p>랜덤 포레스트의 서브세트 데이터의 데이터 건수는 전체 데이터 건수와 동일하지만, 
중복을 허용한 샘플링 방식인 부트스래핑 분할 방식을 사용하기 때문에 개별 데이터가 중첩되어 만들어진다. </p>
<p>랜덤포레스트와 배깅과의 차이점은 랜덤포레스트는 결정트리만 사용한다는 점이다. 
결정 트리의 기본 방식에서는 매 노드마다 전체 피처 중에서 가장 좋은 피처를 골라서 분할함
랜덤포레스트는 각 노드마다 전체 피처 중 일부만 무작위로 뽑아서, 그 중에서만 최적의 피처를 골라서 분할한다.</p>
<hr />
<table>
<thead>
<tr>
<th>앙상블방식</th>
<th>비유</th>
</tr>
</thead>
<tbody><tr>
<td>보팅</td>
<td>다양한 전문가들이 회의해서 다수결로 결정</td>
</tr>
<tr>
<td>배깅</td>
<td>같은 전문가에게 다른 문제지를 주고 답을 받은 뒤 평균</td>
</tr>
<tr>
<td>부스팅</td>
<td>전문가가 틀린 문제를 복습해서 점점 실력을 쌓아가는 방식</td>
</tr>
</tbody></table>
<hr />
<table>
<thead>
<tr>
<th>상황</th>
<th>추천 앙상블</th>
</tr>
</thead>
<tbody><tr>
<td>여러 알고리즘을 조합하고 싶을 때</td>
<td>보팅</td>
</tr>
<tr>
<td>과적합이 걱정되거나 안정성이 필요할 때</td>
<td>배깅 (랜덤포레스트)</td>
</tr>
<tr>
<td>성능이 정말 중요하고 시간 투자 가능할 때</td>
<td>부스팅 (XGBoost, LightGBM)</td>
</tr>
</tbody></table>
<hr />
<p><strong>앙상블 학습이란?</strong></p>
<ul>
<li>집단지성으로 어려운 문제도 쉽게 해결책을 찾을 수 있는 것</li>
<li>여러 분류기의 예측을 결합해 더 정확한 예측을 도출하는 기법</li>
</ul>
<p><strong>앙상블 학습의 유형</strong></p>
<ul>
<li>보팅(voting)</li>
<li>배깅(bagging)</li>
<li>부스팅(boosting) : 이전 모델이 틀린 데이터를 다음 모델이 집중해서 학습하도록 순차적으로 강화하는 앙상블 기법</li>
</ul>
<table>
<thead>
<tr>
<th>구분</th>
<th>보팅 (Voting)</th>
<th>배깅 (Bagging)</th>
<th>부스팅 (Boosting)</th>
</tr>
</thead>
<tbody><tr>
<td>모델 유형</td>
<td><strong>서로 다른 모델</strong> 결합 (예: SVM + DT + LR)</td>
<td><strong>같은 모델</strong> 여러 개 (예: 여러 트리)</td>
<td><strong>같은 모델</strong> 여러 개, 순차적으로 학습</td>
</tr>
<tr>
<td>학습 방식</td>
<td>모델들이 <strong>독립적으로 학습</strong>됨</td>
<td>각각의 모델이 <strong>독립적으로 학습</strong>됨</td>
<td>이전 모델의 <strong>오류를 보완하며 순차적으로 학습</strong></td>
</tr>
<tr>
<td>예측 방식</td>
<td>다수결 or 확률 평균</td>
<td>다수결(분류), 평균(회귀)</td>
<td>각 모델의 결과를 가중합해서 예측</td>
</tr>
<tr>
<td>목적</td>
<td>다양한 시각에서 판단</td>
<td>과적합 줄이고 안정성 향상</td>
<td>약한 학습기의 성능 점진적 향상</td>
</tr>
<tr>
<td>예시 알고리즘</td>
<td><code>VotingClassifier</code>, <code>VotingRegressor</code></td>
<td><code>RandomForest</code></td>
<td><code>GradientBoosting</code>, <code>XGBoost</code>, <code>LightGBM</code></td>
</tr>
</tbody></table>
<hr />
<p><strong>랜덤포레스트란?</strong></p>
<ul>
<li>배깅 방법의 대표적인 알고리즘</li>
<li>부트스트래핑으로 데이터 샘플링(랜덤 복원 추출)</li>
<li>샘플링된 서브 데이터셋의 크기는 원본 데이터와 동일하다.</li>
<li>학습한 여러 개의 결정 트리 결과는 다수결(분류) 또는 평균(회귀) 방식으로 결합한다.</li>
</ul>
<p><strong>배깅 vs 랜덤포레스트</strong></p>
<ul>
<li>랜덤포레스트는 결정트리 모델만 사용한다.</li>
<li>랜덤포레스트는 각 트리 학습 도중, 노드 분할 시 일부 피처만 무작위 선택한다.</li>
<li>배깅은 피쳐선택 단계에서 전체 피처를 사용 가능하다.</li>
</ul>
